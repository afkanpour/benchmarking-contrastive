Wed May 15 18:38:32 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:2F:00.0 Off |                    0 |
| N/A   40C    P8    16W /  70W |      0MiB / 15360MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Tesla T4            On   | 00000000:30:00.0 Off |                    0 |
| N/A   38C    P8    15W /  70W |      0MiB / 15360MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
SLURM_ARRAY_JOB_ID=
SLURM_JOBID=12620870
Running retrieval on ROCO...
/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transform.py:378: UserWarning: Unused augmentation cfg items, specify `use_timm` to use (['quilt_crop', 'num_views']).
  warnings.warn(f'Unused augmentation cfg items, specify `use_timm` to use ({list(aug_cfg_dict.keys())}).')
Models: [('ViT-B-32', '/projects/multimodal/checkpoints/hp_tuning/HPtuning_batchsize_32/checkpoints/epoch_6.pt')]
Datasets: ['roco']
Languages: ['en']
Running 'zeroshot_retrieval' on 'roco' with the model '/projects/multimodal/checkpoints/hp_tuning/HPtuning_batchsize_32/checkpoints/epoch_6.pt' on language 'en'
Number of parameters:  151277313
!!!Using cached dataset
Dataset size: 8176
Dataset split: test
/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transform.py:378: UserWarning: Unused augmentation cfg items, specify `use_timm` to use (['quilt_crop', 'num_views']).
  warnings.warn(f'Unused augmentation cfg items, specify `use_timm` to use ({list(aug_cfg_dict.keys())}).')
Models: [('ViT-B-32', '/projects/multimodal/checkpoints/hp_tuning/HPtuning_batchsize_32/checkpoints/epoch_6.pt')]
Datasets: ['roco']
Languages: ['en']
Running 'zeroshot_retrieval' on 'roco' with the model '/projects/multimodal/checkpoints/hp_tuning/HPtuning_batchsize_32/checkpoints/epoch_6.pt' on language 'en'
Number of parameters:  151277313
!!!Using cached dataset
Dataset size: 8176
Dataset split: test
0it [00:00, ?it/s]0it [00:05, ?it/s]
Traceback (most recent call last):
  File "clip_benchmark/cli.py", line 693, in <module>
    sys.exit(main())  # pragma: no cover
  File "clip_benchmark/cli.py", line 280, in main
    main_eval(base)
  File "clip_benchmark/cli.py", line 398, in main_eval
    run(args)
  File "clip_benchmark/cli.py", line 558, in run
    amp=args.amp,
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/clip_benchmark/metrics/zeroshot_retrieval.py", line 54, in evaluate
    batch_texts_emb = F.normalize(model.encode_text(batch_texts_tok), dim=-1)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/model.py", line 315, in encode_text
    x = self.transformer(x, attn_mask=self.attn_mask)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 390, in forward
    x = r(x, attn_mask=attn_mask)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 263, in forward
    self.attention(q_x=self.ln_1(q_x), k_x=k_x, v_x=v_x, attn_mask=attn_mask)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 246, in attention
    return self.attn(q_x, k_x, v_x, need_weights=False, attn_mask=attn_mask)[0]
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/activation.py", line 1174, in forward
    attn_mask=attn_mask, average_attn_weights=average_attn_weights)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/functional.py", line 5161, in multi_head_attention_forward
    attn_output_weights = softmax(attn_output_weights, dim=-1)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/functional.py", line 1841, in softmax
    ret = input.softmax(dim)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 844.00 MiB (GPU 0; 14.75 GiB total capacity; 3.91 GiB already allocated; 360.81 MiB free; 4.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: gpu078: task 0: Exited with exit code 1
srun: Job step aborted: Waiting up to 62 seconds for job step to finish.
slurmstepd: error: *** JOB 12620870 ON gpu078 CANCELLED AT 2024-05-15T18:40:11 ***
slurmstepd: error: *** STEP 12620870.0 ON gpu078 CANCELLED AT 2024-05-15T18:40:11 ***
