Wed May 15 19:43:48 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:2F:00.0 Off |                    0 |
| N/A   54C    P8    18W /  70W |      0MiB / 15360MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Tesla T4            On   | 00000000:86:00.0 Off |                    0 |
| N/A   35C    P8    15W /  70W |      0MiB / 15360MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
SLURM_ARRAY_JOB_ID=
SLURM_JOBID=12621157
Running retrieval on DeepEyeNet...
/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transform.py:378: UserWarning: Unused augmentation cfg items, specify `use_timm` to use (['quilt_crop', 'num_views']).
  warnings.warn(f'Unused augmentation cfg items, specify `use_timm` to use ({list(aug_cfg_dict.keys())}).')
Models: [('ViT-B-32', '/projects/multimodal/checkpoints/hp_tuning/HPtuning_batchsize_32/checkpoints/epoch_6.pt')]
Datasets: ['deepeyenet']
Languages: ['en']
Running 'zeroshot_retrieval' on 'deepeyenet' with the model '/projects/multimodal/checkpoints/hp_tuning/HPtuning_batchsize_32/checkpoints/epoch_6.pt' on language 'en'
Number of parameters:  151277313
Dataset size: 3140
Dataset split: test
/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transform.py:378: UserWarning: Unused augmentation cfg items, specify `use_timm` to use (['quilt_crop', 'num_views']).
  warnings.warn(f'Unused augmentation cfg items, specify `use_timm` to use ({list(aug_cfg_dict.keys())}).')
Models: [('ViT-B-32', '/projects/multimodal/checkpoints/hp_tuning/HPtuning_batchsize_32/checkpoints/epoch_6.pt')]
Datasets: ['deepeyenet']
Languages: ['en']
Running 'zeroshot_retrieval' on 'deepeyenet' with the model '/projects/multimodal/checkpoints/hp_tuning/HPtuning_batchsize_32/checkpoints/epoch_6.pt' on language 'en'
Number of parameters:  151277313
Dataset size: 3140
Dataset split: test
0it [00:00, ?it/s]1it [00:05,  5.12s/it]2it [00:06,  2.82s/it]3it [00:07,  2.01s/it]4it [00:08,  1.74s/it]5it [00:09,  1.34s/it]6it [00:10,  1.29s/it]7it [00:11,  1.23s/it]8it [00:12,  1.22s/it]9it [00:13,  1.15s/it]10it [00:14,  1.06s/it]11it [00:15,  1.01it/s]12it [00:16,  1.06it/s]13it [00:17,  1.15it/s]14it [00:17,  1.21it/s]15it [00:18,  1.22it/s]16it [00:19,  1.19it/s]17it [00:20,  1.17it/s]18it [00:21,  1.13it/s]19it [00:22,  1.10it/s]20it [00:23,  1.09it/s]21it [00:24,  1.10it/s]22it [00:24,  1.11it/s]23it [00:25,  1.12it/s]24it [00:26,  1.11it/s]25it [00:27,  1.12it/s]26it [00:28,  1.17it/s]27it [00:29,  1.23it/s]28it [00:29,  1.22it/s]29it [00:30,  1.23it/s]30it [00:31,  1.22it/s]31it [00:32,  1.22it/s]32it [00:33,  1.24it/s]33it [00:33,  1.25it/s]34it [00:34,  1.26it/s]35it [00:35,  1.27it/s]36it [00:36,  1.27it/s]37it [00:37,  1.20it/s]38it [00:39,  1.14s/it]39it [00:40,  1.29s/it]40it [00:42,  1.45s/it]41it [00:43,  1.43s/it]42it [00:45,  1.34s/it]43it 0it [00:00, ?it/s]1it [00:05,  5.19s/it]2it [00:06,  2.85s/it]3it [00:07,  2.03s/it]4it [00:08,  1.77s/it]5it [00:09,  1.52s/it]6it [00:11,  1.44s/it]7it [00:12,  1.32s/it]8it [00:13,  1.28s/it]9it [00:14,  1.13s/it]10it [00:15,  1.06s/it]11it [00:15,  1.02it/s]12it [00:16,  1.05it/s]13it [00:17,  1.21it/s]14it [00:18,  1.19it/s]15it [00:19,  1.20it/s]16it [00:20,  1.16it/s]17it [00:20,  1.15it/s]18it [00:21,  1.13it/s]19it [00:22,  1.06it/s]20it [00:23,  1.10it/s]21it [00:24,  1.10it/s]22it [00:25,  1.12it/s]23it [00:26,  1.11it/s]24it [00:27,  1.11it/s]25it [00:28,  1.13it/s]26it [00:28,  1.21it/s]27it [00:29,  1.25it/s]28it [00:30,  1.22it/s]29it [00:31,  1.22it/s]30it [00:32,  1.22it/s]31it [00:32,  1.23it/s]32it [00:33,  1.25it/s]33it [00:34,  1.26it/s]34it [00:35,  1.27it/s]35it [00:35,  1.27it/s]36it [00:36,  1.27it/s]37it [00:37,  1.13it/s]38it [00:39,  1.22s/it]39it [00:41,  1.33s/it]40it [00:43,  1.52s/it]41it [00:44,  1.42s/it]42it [00:45,  1.32s/it]43it [00:46,  1.34s/it]44it [00:47,  1.23s/it]45it [00:48,  1.18s/it]46it [00:49,  1.15s/it]47it [00:50,  1.08s/it]48it [00:51,  1.04s/it]49it [00:52,  1.04it/s]50it [00:52,  1.11it/s]51it [00:54,  1.03it/s]52it [00:55,  1.06s/it]53it [00:56,  1.11s/it]54it [00:58,  1.32s/it]55it [01:00,  1.41s/it]56it [01:01,  1.48s/it]57it [01:02,  1.40s/it]58it [01:03,  1.26s/it]59it [01:04,  1.19s/it]60it [01:05,  1.17s/it]61it [01:07,  1.16s/it]62it [01:08,  1.12s/it]63it [01:09,  1.10s/it]64it [01:10,  1.12s/it]65it [01:11,  1.13s/it]66it [01:12,  1.16s/it]67it [01:13,  1.09s/it]68it [01:14,  1.04s/it]69it [01:15,  1.06s/it]70it [01:16,  1.05s/it]71it [01:17,  1.04s/it]72it [01:18,  1.06s/it]73it [01:19,  1.03s/it]74it [01:20,  1.08it/s]75it [01:21,  1.14it/s]76it [01:22,  1.12it/s]77it [01:23,  1.06it/s]78it [01:24,  1.02s/it]79it [01:25,  1.06s/it]80it [01:26,  1.06s/it]81it [01:27,  1.01s/it]82it [01:28,  1.02s/it]83it [01:29,  1.03s/it]84it [01:30,  1.04s/it]85it [01:31,  1.08s/i[00:47,  1.33s/it]44it [00:47,  1.18s/it]45it [00:49,  1.21s/it]46it [00:50,  1.14s/it]47it [00:51,  1.07s/it]48it [00:51,  1.03s/it]49it [00:52,  1.11it/s]50it [00:53,  1.11it/s]51it [00:54,  1.02s/it]52it [00:56,  1.11s/it]53it [00:57,  1.10s/it]54it [00:59,  1.45s/it]55it [01:00,  1.45s/it]56it [01:02,  1.51s/it]57it [01:03,  1.31s/it]58it [01:04,  1.21s/it]59it [01:05,  1.14s/it]60it [01:06,  1.18s/it]61it [01:07,  1.15s/it]62it [01:08,  1.09s/it]63it [01:09,  1.11s/it]64it [01:10,  1.12s/it]65it [01:12,  1.13s/it]66it [01:13,  1.18s/it]67it [01:14,  1.02s/it]68it [01:15,  1.05s/it]69it [01:16,  1.07s/it]70it [01:17,  1.04s/it]71it [01:18,  1.05s/it]72it [01:19,  1.08s/it]73it [01:20,  1.02it/s]74it [01:20,  1.15it/s]75it [01:21,  1.14it/s]76it [01:22,  1.10it/s]77it [01:23,  1.02it/s]78it [01:25,  1.05s/it]79it [01:26,  1.07s/it]80it [01:27,  1.05s/it]81it [01:27,  1.02it/s]82it [01:29,  1.03s/it]83it [01:30,  1.04s/it]84it [01:31,  1.05s/it]85it [01:32,  1.11s/it]86it [01:33,  1.11s/it]87it [01:35,  1.48s/it]88it [01:36,  1.48s/it]89it [01:38,  1.38s/it]90it [01:39,  1.32s/it]91it [01:40,  1.29s/it]92it [01:41,  1.27s/it]93it [01:42,  1.23s/it]94it [01:43,  1.21s/it]95it [01:45,  1.19s/it]96it [01:46,  1.18s/it]97it [01:47,  1.17s/it]98it [01:48,  1.19s/it]99it [01:49,  1.20s/it]100it [01:51,  1.29s/it]101it [01:52,  1.29s/it]102it [01:53,  1.26s/it]103it [01:54,  1.24s/it]104it [01:56,  1.26s/it]105it [01:57,  1.24s/it]106it [01:59,  1.39s/it]107it [02:00,  1.45s/it]108it [02:02,  1.48s/it]109it [02:03,  1.46s/it]110it [02:04,  1.35s/it]111it [02:05,  1.19s/it]112it [02:07,  1.52s/it]113it [02:10,  1.92s/it]114it [02:13,  2.19s/it]115it [02:16,  2.27s/it]116it [02:17,  2.00s/it]117it [02:19,  1.87s/it]118it [02:20,  1.72s/it]119it [02:21,  1.53s/it]120it [02:22,  1.30s/it]121it [02:22,  1.05s/it]122it [02:23,  1.15it/s]123it [02:23,  1.22it/s]124it [02:25,  1.00it/s]125it [02:26,  1.09s/it]126it [02:27,  1.08s/it]127it [02:t]86it [01:33,  1.11s/it]87it [01:36,  1.65s/it]88it [01:37,  1.43s/it]89it [01:38,  1.35s/it]90it [01:39,  1.31s/it]91it [01:41,  1.28s/it]92it [01:42,  1.25s/it]93it [01:43,  1.23s/it]94it [01:44,  1.19s/it]95it [01:45,  1.19s/it]96it [01:46,  1.16s/it]97it [01:48,  1.19s/it]98it [01:49,  1.21s/it]99it [01:50,  1.22s/it]100it [01:52,  1.32s/it]101it [01:53,  1.28s/it]102it [01:54,  1.24s/it]103it [01:55,  1.24s/it]104it [01:56,  1.24s/it]105it [01:58,  1.24s/it]106it [02:00,  1.45s/it]107it [02:01,  1.46s/it]108it [02:03,  1.49s/it]109it [02:04,  1.46s/it]110it [02:05,  1.28s/it]111it [02:06,  1.11s/it]112it [02:08,  1.63s/it]113it [02:11,  2.00s/it]114it [02:14,  2.26s/it]115it [02:17,  2.31s/it]116it [02:18,  1.90s/it]117it [02:20,  1.93s/it]118it [02:21,  1.65s/it]119it [02:22,  1.49s/it]120it [02:22,  1.17s/it]121it [02:23,  1.05it/s]122it [02:23,  1.25it/s]123it [02:24,  1.17it/s]124it [02:26,  1.12s/it]125it [02:27,  1.09s/it]126it [02:28,  1.08s/it]127it [02:28,  1.07s/it]128it [02:29,  1.06s/it]129it [02:30,  1.01it/s]130it [02:31,  1.13it/s]131it [02:31,  1.25it/s]132it [02:32,  1.35it/s]133it [02:33,  1.44it/s]134it [02:33,  1.50it/s]135it [02:34,  1.54it/s]136it [02:34,  1.57it/s]137it [02:35,  1.60it/s]138it [02:36,  1.62it/s]139it [02:36,  1.53it/s]140it [02:37,  1.44it/s]141it [02:38,  1.47it/s]142it [02:38,  1.49it/s]143it [02:39,  1.33it/s]144it [02:40,  1.17it/s]145it [02:42,  1.07it/s]146it [02:43,  1.01it/s]147it [02:44,  1.02s/it]148it [02:45,  1.04s/it]149it [02:46,  1.06s/it]150it [02:47,  1.05s/it]151it [02:48,  1.03s/it]152it [02:49,  1.03s/it]153it [02:50,  1.02s/it]154it [02:51,  1.01s/it]155it [02:52,  1.01s/it]156it [02:53,  1.05s/it]157it [02:54,  1.06s/it]158it [02:55,  1.07s/it]159it [02:56,  1.08s/it]160it [02:57,  1.07s/it]161it [02:58,  1.07s/it]162it [03:00,  1.10s/it]163it [03:01,  1.10s/it]164it [03:02,  1.10s/it]165it [03:03,  1.12s/it]166it [03:04,  1.09s/it]167it [03:05,  1.08s/it]168it [0329,  1.07s/it]128it [02:30,  1.05s/it]129it [02:30,  1.07it/s]130it [02:31,  1.20it/s]131it [02:32,  1.31it/s]132it [02:32,  1.40it/s]133it [02:33,  1.47it/s]134it [02:33,  1.52it/s]135it [02:34,  1.56it/s]136it [02:35,  1.59it/s]137it [02:35,  1.61it/s]138it [02:36,  1.64it/s]139it [02:37,  1.44it/s]140it [02:37,  1.43it/s]141it [02:38,  1.51it/s]142it [02:39,  1.47it/s]143it [02:40,  1.25it/s]144it [02:41,  1.09it/s]145it [02:42,  1.03it/s]146it [02:43,  1.01s/it]147it [02:44,  1.04s/it]148it [02:45,  1.05s/it]149it [02:47,  1.07s/it]150it [02:47,  1.02s/it]151it [02:48,  1.02s/it]152it [02:50,  1.05s/it]153it [02:50,  1.00s/it]154it [02:51,  1.00it/s]155it [02:53,  1.03s/it]156it [02:54,  1.06s/it]157it [02:55,  1.07s/it]158it [02:56,  1.07s/it]159it [02:57,  1.08s/it]160it [02:58,  1.05s/it]161it [02:59,  1.07s/it]162it [03:00,  1.09s/it]163it [03:01,  1.11s/it]164it [03:02,  1.09s/it]165it [03:03,  1.08s/it]166it [03:05,  1.06s/it]167it [03:06,  1.07s/it]168it [03:06,  1.09s/it]169it [03:07,  1.09s/it]170it [03:08,  1.08s/it]171it [03:09,  1.08s/it]172it [03:10,  1.05s/it]173it [03:11,  1.03s/it]174it [03:12,  1.04s/it]175it [03:14,  1.06s/it]176it [03:15,  1.08s/it]177it [03:16,  1.07s/it]178it [03:17,  1.07s/it]179it [03:18,  1.07s/it]180it [03:19,  1.08s/it]181it [03:20,  1.07s/it]182it [03:21,  1.06s/it]183it [03:22,  1.07s/it]184it [03:23,  1.04s/it]185it [03:24,  1.01s/it]186it [03:25,  1.01s/it]187it [03:26,  1.03s/it]188it [03:27,  1.06s/it]189it [03:28,  1.10s/it]190it [03:30,  1.10s/it]191it [03:31,  1.07s/it]192it [03:32,  1.06s/it]193it [03:33,  1.08s/it]194it [03:34,  1.08s/it]195it [03:35,  1.09s/it]196it [03:36,  1.11s/it]197it [03:37,  1.09s/it]198it [03:38,  1.07s/it]199it [03:39,  1.07s/it]200it [03:40,  1.06s/it]201it [03:41,  1.07s/it]202it [03:42,  1.09s/it]203it [03:43,  1.07s/it]204it [03:45,  1.08s/it]205it [03:46,  1.09s/it]206it [03:47,  1.09s/it]207it [03:48,  1.08s/it]208it [03:49,  1.07s/it]209it [0:07,  1.07s/it]169it [03:08,  1.09s/it]170it [03:09,  1.09s/it]171it [03:10,  1.07s/it]172it [03:11,  1.07s/it]173it [03:12,  1.02s/it]174it [03:13,  1.05s/it]175it [03:14,  1.08s/it]176it [03:15,  1.09s/it]177it [03:16,  1.08s/it]178it [03:17,  1.07s/it]179it [03:18,  1.08s/it]180it [03:20,  1.09s/it]181it [03:21,  1.05s/it]182it [03:22,  1.05s/it]183it [03:23,  1.07s/it]184it [03:24,  1.01s/it]185it [03:25,  1.01s/it]186it [03:26,  1.03s/it]187it [03:27,  1.05s/it]188it [03:28,  1.06s/it]189it [03:29,  1.10s/it]190it [03:30,  1.10s/it]191it [03:31,  1.06s/it]192it [03:32,  1.06s/it]193it [03:33,  1.08s/it]194it [03:34,  1.09s/it]195it [03:36,  1.11s/it]196it [03:37,  1.11s/it]197it [03:38,  1.09s/it]198it [03:39,  1.07s/it]199it [03:40,  1.06s/it]200it [03:41,  1.06s/it]201it [03:42,  1.08s/it]202it [03:43,  1.09s/it]203it [03:44,  1.06s/it]204it [03:45,  1.08s/it]205it [03:46,  1.09s/it]206it [03:47,  1.09s/it]207it [03:48,  1.08s/it]208it [03:50,  1.08s/it]209it [03:50,  1.08s/it]210it [03:51,  1.05s/it]211it [03:52,  1.04s/it]212it [03:53,  1.06s/it]213it [03:54,  1.08s/it]214it [03:55,  1.08s/it]215it [03:56,  1.08s/it]216it [03:57,  1.08s/it]217it [03:59,  1.11s/it]218it [04:00,  1.11s/it]219it [04:01,  1.02s/it]220it [04:01,  1.13it/s]221it [04:02,  1.28it/s]222it [04:02,  1.41it/s]223it [04:03,  1.54it/s]224it [04:03,  1.61it/s]225it [04:04,  1.70it/s]226it [04:04,  1.90it/s]227it [04:05,  2.16it/s]228it [04:05,  2.18it/s]229it [04:06,  1.74it/s]230it [04:07,  1.58it/s]231it [04:07,  1.61it/s]232it [04:08,  1.65it/s]233it [04:08,  1.68it/s]234it [04:09,  1.66it/s]235it [04:10,  1.66it/s]236it [04:10,  1.71it/s]237it [04:11,  1.76it/s]238it [04:12,  1.37it/s]239it [04:13,  1.30it/s]240it [04:13,  1.39it/s]241it [04:14,  1.40it/s]242it [04:15,  1.43it/s]243it [04:15,  1.47it/s]244it [04:16,  1.38it/s]245it [04:17,  1.39it/s]246it [04:17,  1.42it/s]247it [04:19,  1.14it/s]248it [04:20,  1.14it/s]249it [04:20,  1.28it/s]250it [3:51,  1.09s/it]210it [03:52,  1.03s/it]211it [03:53,  1.06s/it]212it [03:54,  1.06s/it]213it [03:55,  1.09s/it]214it [03:56,  1.09s/it]215it [03:57,  1.07s/it]216it [03:58,  1.10s/it]217it [03:59,  1.12s/it]218it [04:00,  1.10s/it]219it [04:01,  1.06it/s]220it [04:01,  1.22it/s]221it [04:02,  1.33it/s]222it [04:03,  1.49it/s]223it [04:03,  1.60it/s]224it [04:04,  1.63it/s]225it [04:04,  1.78it/s]226it [04:04,  2.04it/s]227it [04:05,  2.32it/s]228it [04:05,  2.07it/s]229it [04:06,  1.54it/s]230it [04:07,  1.60it/s]231it [04:08,  1.61it/s]232it [04:08,  1.67it/s]233it [04:09,  1.68it/s]234it [04:09,  1.63it/s]235it [04:10,  1.68it/s]236it [04:10,  1.73it/s]237it [04:11,  1.79it/s]238it [04:12,  1.22it/s]239it [04:13,  1.35it/s]240it [04:14,  1.42it/s]241it [04:14,  1.37it/s]242it [04:15,  1.47it/s]243it [04:16,  1.44it/s]244it [04:17,  1.31it/s]245it [04:17,  1.46it/s]246it [04:18,  1.38it/s]247it [04:19,  1.05it/s]248it [04:20,  1.20it/s]249it [04:20,  1.33it/s]250it [04:21,  1.37it/s]251it [04:21,  1.41it/s]252it [04:22,  1.42it/s]253it [04:23,  1.40it/s]254it [04:24,  1.32it/s]255it [04:25,  1.03it/s]256it [04:26,  1.01s/it]257it [04:29,  1.63s/it]258it [04:31,  1.54s/it]259it [04:32,  1.35s/it]260it [04:32,  1.14s/it]261it [04:33,  1.05s/it]262it [04:36,  1.67s/it]263it [04:40,  2.38s/it]264it [04:42,  2.32s/it]265it [04:44,  2.14s/it]266it [04:46,  1.98s/it]267it [04:47,  1.74s/it]268it [04:47,  1.40s/it]269it [04:48,  1.19s/it]270it [04:50,  1.37s/it]271it [04:51,  1.26s/it]272it [04:53,  1.56s/it]273it [04:55,  1.62s/it]274it [04:56,  1.57s/it]275it [04:58,  1.44s/it]276it [04:58,  1.28s/it]277it [04:59,  1.15s/it]278it [05:01,  1.43s/it]279it [05:03,  1.55s/it]280it [05:04,  1.43s/it]281it [05:05,  1.25s/it]282it [05:06,  1.13s/it]283it [05:08,  1.43s/it]284it [05:10,  1.55s/it]285it [05:12,  1.54s/it]286it [05:13,  1.51s/it]287it [05:14,  1.43s/it]288it [05:16,  1.57s/it]289it [05:19,  1.93s/it]290it [05:22,  2.32s/it]291it 04:21,  1.40it/s]251it [04:22,  1.41it/s]252it [04:22,  1.42it/s]253it [04:23,  1.38it/s]254it [04:24,  1.29it/s]255it [04:26,  1.09s/it]256it [04:27,  1.05it/s]257it [04:30,  1.71s/it]258it [04:31,  1.56s/it]259it [04:32,  1.28s/it]260it [04:33,  1.09s/it]261it [04:34,  1.05s/it]262it [04:37,  1.81s/it]263it [04:41,  2.52s/it]264it [04:43,  2.41s/it]265it [04:45,  2.17s/it]266it [04:47,  1.99s/it]267it [04:47,  1.60s/it]268it [04:48,  1.26s/it]269it [04:49,  1.13s/it]270it [04:51,  1.47s/it]271it [04:51,  1.13s/it]272it [04:54,  1.66s/it]273it [04:56,  1.67s/it]274it [04:57,  1.58s/it]275it [04:58,  1.39s/it]276it [04:59,  1.24s/it]277it [05:00,  1.11s/it]278it [05:02,  1.52s/it]279it [05:04,  1.60s/it]280it [05:05,  1.36s/it]281it [05:06,  1.21s/it]282it [05:07,  1.09s/it]283it [05:09,  1.54s/it]284it [05:11,  1.61s/it]285it [05:12,  1.55s/it]286it [05:14,  1.51s/it]287it [05:15,  1.41s/it]288it [05:17,  1.64s/it]289it [05:20,  2.00s/it]290it [05:23,  2.37s/it]291it [05:25,  2.60s/it]292it [05:29,  3.05s/it]293it [05:33,  3.06s/it]294it [05:34,  2.64s/it]294it [05:36,  1.14s/it]
[05:26,  2.62s/it]292it [05:31,  3.22s/it]293it [05:34,  3.13s/it]294it [05:35,  2.48s/it]294it [05:36,  1.14s/it]
Traceback (most recent call last):
  File "clip_benchmark/cli.py", line 693, in <module>
    sys.exit(main())  # pragma: no cover
  File "clip_benchmark/cli.py", line 280, in main
    main_eval(base)
  File "clip_benchmark/cli.py", line 398, in main_eval
    run(args)
  File "clip_benchmark/cli.py", line 558, in run
    amp=args.amp,
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/clip_benchmark/metrics/zeroshot_retrieval.py", line 54, in evaluate
    batch_texts_emb = F.normalize(model.encode_text(batch_texts_tok), dim=-1)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/model.py", line 315, in encode_text
    x = self.transformer(x, attn_mask=self.attn_mask)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 390, in forward
    x = r(x, attn_mask=attn_mask)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 263, in forward
    self.attention(q_x=self.ln_1(q_x), k_x=k_x, v_x=v_x, attn_mask=attn_mask)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 246, in attention
    return self.attn(q_x, k_x, v_x, need_weights=False, attn_mask=attn_mask)[0]
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/activation.py", line 1174, in forward
    attn_mask=attn_mask, average_attn_weights=average_attn_weights)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/functional.py", line 5165, in multi_head_attention_forward
    attn_output = torch.bmm(attn_output_weights, v)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 394.00 MiB (GPU 0; 14.75 GiB total capacity; 5.98 GiB already allocated; 6.81 MiB free; 7.19 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "clip_benchmark/cli.py", line 693, in <module>
    sys.exit(main())  # pragma: no cover
  File "clip_benchmark/cli.py", line 280, in main
    main_eval(base)
  File "clip_benchmark/cli.py", line 398, in main_eval
    run(args)
  File "clip_benchmark/cli.py", line 558, in run
    amp=args.amp,
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/clip_benchmark/metrics/zeroshot_retrieval.py", line 54, in evaluate
    batch_texts_emb = F.normalize(model.encode_text(batch_texts_tok), dim=-1)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/model.py", line 315, in encode_text
    x = self.transformer(x, attn_mask=self.attn_mask)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 390, in forward
    x = r(x, attn_mask=attn_mask)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 263, in forward
    self.attention(q_x=self.ln_1(q_x), k_x=k_x, v_x=v_x, attn_mask=attn_mask)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 246, in attention
    return self.attn(q_x, k_x, v_x, need_weights=False, attn_mask=attn_mask)[0]
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/activation.py", line 1174, in forward
    attn_mask=attn_mask, average_attn_weights=average_attn_weights)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/functional.py", line 5161, in multi_head_attention_forward
    attn_output_weights = softmax(attn_output_weights, dim=-1)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/functional.py", line 1841, in softmax
    ret = input.softmax(dim)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 946.00 MiB (GPU 0; 14.75 GiB total capacity; 4.28 GiB already allocated; 832.81 MiB free; 4.80 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: gpu019: task 0: Exited with exit code 1
srun: error: gpu019: task 1: Exited with exit code 1
Retrieval on DeepEyeNet finished.
