Mon May 13 20:09:27 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A40          On   | 00000000:06:00.0 Off |                    0 |
|  0%   60C    P0    63W / 300W |      0MiB / 46068MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA A40          On   | 00000000:2F:00.0 Off |                    0 |
|  0%   30C    P8    29W / 300W |      0MiB / 46068MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA A40          On   | 00000000:86:00.0 Off |                    0 |
|  0%   28C    P8    30W / 300W |      0MiB / 46068MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA A40          On   | 00000000:D8:00.0 Off |                    0 |
|  0%   28C    P8    28W / 300W |      0MiB / 46068MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
SLURM_ARRAY_JOB_ID=
SLURM_JOBID=12582768
2024-05-13,20:09:40 | INFO | No latest resume checkpoint found in /checkpoint/yaspar/12582768/HPtuning_accumfreq_2/checkpoints.
NCCL version 2.14.3+cuda11.7
2024-05-13,20:09:45 | INFO | Running in distributed mode with multiple processes. Device: cuda:0.Process (global: 0, local 0), total 4.
2024-05-13,20:09:45 | INFO | Loading pretrained ViT-B-32 from OpenAI.
2024-05-13,20:09:45 | INFO | Running in distributed mode with multiple processes. Device: cuda:3.Process (global: 3, local 3), total 4.
2024-05-13,20:09:45 | INFO | Running in distributed mode with multiple processes. Device: cuda:1.Process (global: 1, local 1), total 4.
2024-05-13,20:09:45 | INFO | Running in distributed mode with multiple processes. Device: cuda:2.Process (global: 2, local 2), total 4.
2024-05-13,20:09:45 | INFO | Loading pretrained ViT-B-32 from OpenAI.
2024-05-13,20:09:45 | INFO | Loading pretrained ViT-B-32 from OpenAI.
2024-05-13,20:09:45 | INFO | Loading pretrained ViT-B-32 from OpenAI.
/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transform.py:378: UserWarning: Unused augmentation cfg items, specify `use_timm` to use (['scale', 'quilt_crop', 'num_views']).
  warnings.warn(f'Unused augmentation cfg items, specify `use_timm` to use ({list(aug_cfg_dict.keys())}).')
/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transform.py:378: UserWarning: Unused augmentation cfg items, specify `use_timm` to use (['scale', 'quilt_crop', 'num_views']).
  warnings.warn(f'Unused augmentation cfg items, specify `use_timm` to use ({list(aug_cfg_dict.keys())}).')
/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transform.py:378: UserWarning: Unused augmentation cfg items, specify `use_timm` to use (['scale', 'quilt_crop', 'num_views']).
  warnings.warn(f'Unused augmentation cfg items, specify `use_timm` to use ({list(aug_cfg_dict.keys())}).')
/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transform.py:378: UserWarning: Unused augmentation cfg items, specify `use_timm` to use (['scale', 'quilt_crop', 'num_views']).
  warnings.warn(f'Unused augmentation cfg items, specify `use_timm` to use ({list(aug_cfg_dict.keys())}).')
2024-05-13,20:10:00 | INFO | Model:
2024-05-13,20:10:00 | INFO | CLIP(
  (visual): VisionTransformer(
    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)
    (patch_dropout): Identity()
    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (transformer): Transformer(
      (resblocks): ModuleList(
        (0): ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
        (1): ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
        (2): ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
        (3): ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
        (4): ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
        (5): ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
        (6): ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
        (7): ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
        (8): ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
        (9): ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
        (10): ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
        (11): ResidualAttentionBlock(
          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
          )
          (ls_1): Identity()
          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=768, out_features=3072, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=3072, out_features=768, bias=True)
          )
          (ls_2): Identity()
        )
      )
    )
    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (transformer): Transformer(
    (resblocks): ModuleList(
      (0): ResidualAttentionBlock(
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ls_2): Identity()
      )
      (1): ResidualAttentionBlock(
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ls_2): Identity()
      )
      (2): ResidualAttentionBlock(
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ls_2): Identity()
      )
      (3): ResidualAttentionBlock(
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ls_2): Identity()
      )
      (4): ResidualAttentionBlock(
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ls_2): Identity()
      )
      (5): ResidualAttentionBlock(
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ls_2): Identity()
      )
      (6): ResidualAttentionBlock(
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ls_2): Identity()
      )
      (7): ResidualAttentionBlock(
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ls_2): Identity()
      )
      (8): ResidualAttentionBlock(
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ls_2): Identity()
      )
      (9): ResidualAttentionBlock(
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ls_2): Identity()
      )
      (10): ResidualAttentionBlock(
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ls_2): Identity()
      )
      (11): ResidualAttentionBlock(
        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (ls_1): Identity()
        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (mlp): Sequential(
          (c_fc): Linear(in_features=512, out_features=2048, bias=True)
          (gelu): QuickGELU()
          (c_proj): Linear(in_features=2048, out_features=512, bias=True)
        )
        (ls_2): Identity()
      )
    )
  )
  (token_embedding): Embedding(49408, 512)
  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
)
2024-05-13,20:10:00 | INFO | Params:
2024-05-13,20:10:00 | INFO |   accum_freq: 2
2024-05-13,20:10:00 | INFO |   aug_cfg: {'quilt_crop': True}
2024-05-13,20:10:00 | INFO |   batch_size: 1024
2024-05-13,20:10:00 | INFO |   beta1: 0.9
2024-05-13,20:10:00 | INFO |   beta2: 0.98
2024-05-13,20:10:00 | INFO |   checkpoint_path: /checkpoint/yaspar/12582768/HPtuning_accumfreq_2/checkpoints
2024-05-13,20:10:00 | INFO |   coca_caption_loss_weight: 2.0
2024-05-13,20:10:00 | INFO |   coca_contrastive_loss_weight: 1.0
2024-05-13,20:10:00 | INFO |   copy_codebase: False
2024-05-13,20:10:00 | INFO |   csv_caption_key: title
2024-05-13,20:10:00 | INFO |   csv_img_key: filepath
2024-05-13,20:10:00 | INFO |   csv_img_root: 
2024-05-13,20:10:00 | INFO |   csv_separator: ,
2024-05-13,20:10:00 | INFO |   dataset_resampled: False
2024-05-13,20:10:00 | INFO |   dataset_type: mixed
2024-05-13,20:10:00 | INFO |   ddp_static_graph: False
2024-05-13,20:10:00 | INFO |   debug: False
2024-05-13,20:10:00 | INFO |   delete_previous_checkpoint: False
2024-05-13,20:10:00 | INFO |   device: cuda:0
2024-05-13,20:10:00 | INFO |   dist_backend: nccl
2024-05-13,20:10:00 | INFO |   dist_url: env://
2024-05-13,20:10:00 | INFO |   distill: False
2024-05-13,20:10:00 | INFO |   distill_model: None
2024-05-13,20:10:00 | INFO |   distill_pretrained: None
2024-05-13,20:10:00 | INFO |   distributed: True
2024-05-13,20:10:00 | INFO |   epochs: 20
2024-05-13,20:10:00 | INFO |   epochs_cooldown: None
2024-05-13,20:10:00 | INFO |   eps: 1e-06
2024-05-13,20:10:00 | INFO |   force_custom_text: False
2024-05-13,20:10:00 | INFO |   force_image_size: None
2024-05-13,20:10:00 | INFO |   force_patch_dropout: None
2024-05-13,20:10:00 | INFO |   force_quick_gelu: False
2024-05-13,20:10:00 | INFO |   gather_with_grad: True
2024-05-13,20:10:00 | INFO |   grad_checkpointing: False
2024-05-13,20:10:00 | INFO |   grad_clip_norm: None
2024-05-13,20:10:00 | INFO |   horovod: False
2024-05-13,20:10:00 | INFO |   image_contrast: False
2024-05-13,20:10:00 | INFO |   image_interpolation: None
2024-05-13,20:10:00 | INFO |   image_mean: None
2024-05-13,20:10:00 | INFO |   image_resize_mode: None
2024-05-13,20:10:00 | INFO |   image_std: None
2024-05-13,20:10:00 | INFO |   imagenet_v2: None
2024-05-13,20:10:00 | INFO |   imagenet_val: None
2024-05-13,20:10:00 | INFO |   local_loss: False
2024-05-13,20:10:00 | INFO |   local_rank: 0
2024-05-13,20:10:00 | INFO |   lock_image: False
2024-05-13,20:10:00 | INFO |   lock_image_freeze_bn_stats: False
2024-05-13,20:10:00 | INFO |   lock_image_unlocked_groups: 0
2024-05-13,20:10:00 | INFO |   lock_text: False
2024-05-13,20:10:00 | INFO |   lock_text_decoder: False
2024-05-13,20:10:00 | INFO |   lock_text_freeze_layer_norm: False
2024-05-13,20:10:00 | INFO |   lock_text_unlocked_layers: 0
2024-05-13,20:10:00 | INFO |   log_every_n_steps: 100
2024-05-13,20:10:00 | INFO |   log_level: 20
2024-05-13,20:10:00 | INFO |   log_local: False
2024-05-13,20:10:00 | INFO |   log_path: /checkpoint/yaspar/12582768/HPtuning_accumfreq_2/out.log
2024-05-13,20:10:00 | INFO |   logs: /checkpoint/yaspar/12582768/
2024-05-13,20:10:00 | INFO |   lr: 5e-05
2024-05-13,20:10:00 | INFO |   lr_cooldown_end: 0.0
2024-05-13,20:10:00 | INFO |   lr_cooldown_power: 1.0
2024-05-13,20:10:00 | INFO |   lr_scheduler: cosine
2024-05-13,20:10:00 | INFO |   mask_contrast: False
2024-05-13,20:10:00 | INFO |   model: ViT-B-32
2024-05-13,20:10:00 | INFO |   name: HPtuning_accumfreq_2
2024-05-13,20:10:00 | INFO |   no_set_device_rank: False
2024-05-13,20:10:00 | INFO |   pathmnist: False
2024-05-13,20:10:00 | INFO |   precision: amp
2024-05-13,20:10:00 | INFO |   pretrained: openai
2024-05-13,20:10:00 | INFO |   pretrained_image: False
2024-05-13,20:10:00 | INFO |   quilt_roi_selection_prob: 0.0
2024-05-13,20:10:00 | INFO |   rank: 0
2024-05-13,20:10:00 | INFO |   remote_sync: None
2024-05-13,20:10:00 | INFO |   remote_sync_frequency: 300
2024-05-13,20:10:00 | INFO |   remote_sync_protocol: s3
2024-05-13,20:10:00 | INFO |   report_to: wandb
2024-05-13,20:10:00 | INFO |   resume: None
2024-05-13,20:10:00 | INFO |   save_frequency: 1
2024-05-13,20:10:00 | INFO |   save_most_recent: False
2024-05-13,20:10:00 | INFO |   seed: 0
2024-05-13,20:10:00 | INFO |   siglip: False
2024-05-13,20:10:00 | INFO |   skip_scheduler: False
2024-05-13,20:10:00 | INFO |   tensorboard: False
2024-05-13,20:10:00 | INFO |   tensorboard_path: 
2024-05-13,20:10:00 | INFO |   torchcompile: False
2024-05-13,20:10:00 | INFO |   torchscript: False
2024-05-13,20:10:00 | INFO |   trace: False
2024-05-13,20:10:00 | INFO |   train_data: /projects/multimodal/datasets/pmc_oa/train.jsonl::/projects/multimodal/datasets/Quilt_1M/quilt_1m_train.csv::/projects/multimodal/datasets/mimic_cxr/mimic_cxr_double_image_train.csv::/projects/aieng/multimodal/datasets/roco/cache/radiologytraindata.csv
2024-05-13,20:10:00 | INFO |   train_data_upsampling_factors: None
2024-05-13,20:10:00 | INFO |   train_num_samples: 2769337
2024-05-13,20:10:00 | INFO |   use_bn_sync: False
2024-05-13,20:10:00 | INFO |   use_bnb_linear: None
2024-05-13,20:10:00 | INFO |   val_data: /projects/multimodal/datasets/pmc_oa/valid.jsonl
2024-05-13,20:10:00 | INFO |   val_frequency: 1
2024-05-13,20:10:00 | INFO |   val_no_retrieval: True
2024-05-13,20:10:00 | INFO |   val_num_samples: None
2024-05-13,20:10:00 | INFO |   wandb: True
2024-05-13,20:10:00 | INFO |   wandb_notes: 
2024-05-13,20:10:00 | INFO |   wandb_offline: False
2024-05-13,20:10:00 | INFO |   wandb_project_name: open-multi-modal
2024-05-13,20:10:00 | INFO |   warmup: 0
2024-05-13,20:10:00 | INFO |   wd: 0.1
2024-05-13,20:10:00 | INFO |   workers: 4
2024-05-13,20:10:00 | INFO |   world_size: 4
2024-05-13,20:10:00 | INFO |   zeroshot_frequency: 1
2024-05-13,20:10:46 | INFO | Loaded mixed dataset with 2755782 samples.
2024-05-13,20:10:46 | INFO | Loaded mixed dataset with 2755782 samples.
2024-05-13,20:10:49 | INFO | Loaded mixed dataset with 2755782 samples.
2024-05-13,20:10:49 | INFO | Loaded mixed dataset with 164657 samples.
2024-05-13,20:10:49 | INFO | Loaded mixed dataset with 164657 samples.
2024-05-13,20:10:50 | INFO | Loaded mixed dataset with 2755782 samples.
2024-05-13,20:10:52 | INFO | Loaded mixed dataset with 164657 samples.
2024-05-13,20:10:54 | INFO | Loaded mixed dataset with 164657 samples.
wandb: Currently logged in as: yasaman-parhizkar (vector-institute-aieng). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/wandb/run-20240513_201054-HPtuning_accumfreq_2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run HPtuning_accumfreq_2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/vector-institute-aieng/open-multi-modal
wandb: üöÄ View run at https://wandb.ai/vector-institute-aieng/open-multi-modal/runs/HPtuning_accumfreq_2
wandb: WARNING Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
2024-05-13,20:11:38 | INFO | Eval Epoch: 0 [1024 / 164657]	Clip Loss: 6.555687	
Traceback (most recent call last):
  File "training/main.py", line 620, in <module>
    main(sys.argv[1:])
  File "training/main.py", line 533, in main
    tb_writer=writer,
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/training/train.py", line 145, in train_one_epoch
    model_out = model(images, texts)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/model.py", line 345, in forward
    self.encode_text(text, normalize=True) if text is not None else None
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/model.py", line 315, in encode_text
    x = self.transformer(x, attn_mask=self.attn_mask)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 390, in forward
    x = r(x, attn_mask=attn_mask)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 265, in forward
    x = x + self.ls_2(self.mlp(self.ln_2(x)))
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 37, in forward
    return x * torch.sigmoid(1.702 * x)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 308.00 MiB (GPU 3; 44.56 GiB total capacity; 41.52 GiB already allocated; 264.69 MiB free; 42.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "training/main.py", line 620, in <module>
    main(sys.argv[1:])
  File "training/main.py", line 533, in main
    tb_writer=writer,
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/training/train.py", line 145, in train_one_epoch
    model_out = model(images, texts)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/model.py", line 345, in forward
    self.encode_text(text, normalize=True) if text is not None else None
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/model.py", line 315, in encode_text
    x = self.transformer(x, attn_mask=self.attn_mask)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 390, in forward
    x = r(x, attn_mask=attn_mask)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 265, in forward
    x = x + self.ls_2(self.mlp(self.ln_2(x)))
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 37, in forward
    return x * torch.sigmoid(1.702 * x)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 308.00 MiB (GPU 2; 44.56 GiB total capacity; 41.52 GiB already allocated; 264.69 MiB free; 42.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "training/main.py", line 620, in <module>
    main(sys.argv[1:])
  File "training/main.py", line 533, in main
    tb_writer=writer,
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/training/train.py", line 145, in train_one_epoch
    model_out = model(images, texts)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/model.py", line 345, in forward
    self.encode_text(text, normalize=True) if text is not None else None
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/model.py", line 315, in encode_text
    x = self.transformer(x, attn_mask=self.attn_mask)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 390, in forward
    x = r(x, attn_mask=attn_mask)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 265, in forward
    x = x + self.ls_2(self.mlp(self.ln_2(x)))
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 37, in forward
    return x * torch.sigmoid(1.702 * x)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 308.00 MiB (GPU 1; 44.56 GiB total capacity; 41.52 GiB already allocated; 264.69 MiB free; 42.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
srun: error: gpu056: task 2: Exited with exit code 1
srun: error: gpu056: task 3: Exited with exit code 1
srun: error: gpu056: task 1: Exited with exit code 1
2024-05-13,20:14:35 | INFO | Eval Epoch: 0 [103424 / 164657]	Clip Loss: 6.028048	
2024-05-13,20:16:28 | INFO | Eval Epoch: 0 clip_val_loss: 6.0024	epoch: 0.0000	num_samples: 164657.0000
2024-05-13,20:16:28 | INFO | Start epoch 0
Traceback (most recent call last):
  File "training/main.py", line 620, in <module>
    main(sys.argv[1:])
  File "training/main.py", line 533, in main
    tb_writer=writer,
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/training/train.py", line 145, in train_one_epoch
    model_out = model(images, texts)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/model.py", line 345, in forward
    self.encode_text(text, normalize=True) if text is not None else None
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/model.py", line 315, in encode_text
    x = self.transformer(x, attn_mask=self.attn_mask)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 390, in forward
    x = r(x, attn_mask=attn_mask)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 265, in forward
    x = x + self.ls_2(self.mlp(self.ln_2(x)))
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/fs01/home/yaspar/Documents/envs/mmm/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/fs01/home/yaspar/Documents/GitHub/Multimodal/MedMultiModal/src/open_clip/transformer.py", line 37, in forward
    return x * torch.sigmoid(1.702 * x)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 308.00 MiB (GPU 0; 44.56 GiB total capacity; 41.51 GiB already allocated; 192.69 MiB free; 42.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
wandb: - 0.008 MB of 0.008 MB uploadedwandb: \ 0.021 MB of 0.031 MB uploaded (0.001 MB deduped)wandb: | 0.031 MB of 0.031 MB uploaded (0.001 MB deduped)wandb: 
wandb: Run history:
wandb:             epoch ‚ñÅ
wandb: val/clip_val_loss ‚ñÅ
wandb:         val/epoch ‚ñÅ
wandb:   val/num_samples ‚ñÅ
wandb: 
wandb: Run summary:
wandb:             epoch 0
wandb: val/clip_val_loss 6.00237
wandb:         val/epoch 0
wandb:   val/num_samples 164657
wandb: 
wandb: üöÄ View run HPtuning_accumfreq_2 at: https://wandb.ai/vector-institute-aieng/open-multi-modal/runs/HPtuning_accumfreq_2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/vector-institute-aieng/open-multi-modal
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20240513_201054-HPtuning_accumfreq_2/logs
srun: error: gpu056: task 0: Exited with exit code 1
